# Graph Embeddings Explained

[Graph embeddings explained](https://towardsdatascience.com/graph-embeddings-explained-f0d8d1c49ec)
## Machine Learning on Graphs

A graph consists of a series of pairwise relationships between nodes. ML on graphs can be used to solve problems such as _community detection_, _link prediction_, and _node classification_. See also [Directed Graph](Directed%20Graph.md).

- Link prediction: predict if two nodes currently not linked are linked

To apply ML to graphs, the graphs must be converted into a tabular format. In the past, statistical measures or kernel functions were used. These days, graphs are encoded into embedding vectors.

Machine learning can be used to detect latent patterns in graphs.

## What is Graph Embedding

Feature engineering is used to extract a compact and meaningful representation of the graph. The embedding is then used as input for ML.

One method is to extract statistical measures from the graph, such as degree distributions, page rank scores, centrality metrics, jaccard scores, etc. Kernel functions can also be used to incorporate desired properties into the model. Read [graph kernels](Graph%20Kernels.md) for more.

Graph embedding is the latest trend that yields embeddings on a graph. A model is trained to transform a discrete graph to a continuous space. In the process, it learns to keep information about graph structure in the generated embeddings. Once it is trained, it can be applied to the graph, and the result mapping can be used as a feature set for machine learning.

## Types of Graph Embeddings

### Node Embeddings

An embedding vector is generated for each node. Nodes in close proximity in the original graph should be close in the embedding space. One node embedding method is [Node2Vec](Graph%20Neural%20Network.md#Node2Vec).

Node embeddings can be used for node classification tasks. It can also be used for community detection, which groups similar nodes together.

### Edge Embeddings

Edge embeddings learns the edge attributes provided by the graph. Edge attributes are information related to the edge. There are also node attributes, which are information related to nodes.

For example, in a social network, node attributes are the users' age, gender, hobby, etc. While edge attributes are the number of interactions and type of interactions between two users. Edge embeddings can be used to learn what kind of edge forms between what kind of users. Then ML models can be trained to predict new links. This is link prediction.

Besides link prediction, edge embeddings can be used for edge classification and graph reconstruction. Graph reconstruction refers to reconstructing the graph from the learned embeddings, which can be useful for tasks like anomaly detection or graph summarization.

Edge embeddings can be generated by combining node embeddings or learned directly.
### Graph Embeddings

Graph embeddings generate embeddings for the structure of the whole graph. This can be useful for classifying subgraphs. Graph embeddings are not as common as node and edge embeddings.

## Link Prediction Example

Let's consider an example where edge embeddings are used to study a social network. Specifically, we'll focus on predicting new friendships (link prediction) in a social networking platform like Facebook.

### Scenario: Link Prediction in a Social Network

#### Goal

Predict whether a new friendship will form between two users based on the learned edge embeddings.

#### Data

- **Nodes**: Represent users in the social network.
- **Edges**: Represent friendships between users.
- **Node Attributes**: User features such as age, location, interests, etc.
- **Edge Attributes**: Interaction frequency, types of interactions (messages, likes, comments).

### Steps to Use Edge Embeddings

1. **Graph Representation**
    
    - Construct a graph $G=(V,E)$ where $V$ is the set of users and $E$ is the set of existing friendships.
2. **Node Embeddings**
    
    - Apply a node embedding technique (e.g., Node2Vec, GraphSAGE, or a Graph Neural Network) to generate embeddings for each user. These embeddings capture the structural and attribute information of each node.
3. **Edge Embeddings**
    
    - For each pair of users $(u,v)$, combine their node embeddings to form an edge embedding. Common methods include:
        - **Concatenation**: $\mathbf{e}_{uv​}=[\mathbf{u}∥\mathbf{v}]$
        - **Element-wise Product**: $\mathbf{e}_{uv​}​=\mathbf{u}⊙\mathbf{v}$
        - **Average**: $\mathbf{e}_{uv​}=(\mathbf{u}+\mathbf{v})/2$
4. **Training Data Preparation**
    
    - Use existing friendships (edges) as positive samples.
    - Generate negative samples (non-existing edges) by randomly sampling pairs of users who are not currently friends.
    - Label positive samples as 1 and negative samples as 0.
5. **Train a Classifier**
    
    - Train a machine learning classifier (e.g., logistic regression, [SVM](Support%20Vector%20Machine.md), or a neural network) using the edge embeddings as features and the labels (friendship or not) as targets.
6. **Link Prediction** ^1f1a81
    
    - Use the trained classifier to predict the probability of a new friendship forming between pairs of users based on their edge embeddings.

### Example Implementation

Let's walk through a hypothetical implementation:

1. **Graph Construction**:
    
    - Assume we have a social network with users $U=\{u_1​,u_2​,…,u_n​\}$ and friendships $F=\{(u1​,u2​),(u3​,u4​),…\}$.
2. **Node Embedding Generation**:
    
    - Use Node2Vec to generate embeddings for each user. Each user $u$ has an embedding $\mathbf{u} \in \mathbb{R}^d$.
3. **Edge Embedding Formation**:
    
    - For each friendship $(u_i,u_j)∈F(u_i, u_j)$, form the edge embedding $\mathbf{e}_{ij}$​ by concatenation: $\mathbf{e}_{ij}​=[\mathbf{u_i}​∥\mathbf{u_j}​]$.
4. **Classifier Training**:
    
    - Positive samples: Existing friendships $(u_i,u_j)∈F(u_i, u_j)$.
    - Negative samples: Random pairs $(u_k,u_l)∉F(u_k, u_l)$.
    - Train a logistic regression model on these samples.
5. **Prediction**:
    
    - For a new pair of users $(u_m, u_n)$, form the edge embedding $\mathbf{e}_{mn}$​ and use the trained classifier to predict the probability of them becoming friends.

### Analysis

By using edge embeddings in this manner, we can gain insights into the factors that contribute to the formation of new friendships in the social network. For example, the classifier might reveal that users with similar interests (captured in their node attributes) or users who have many mutual friends (captured in the graph structure) are more likely to form new friendships.

### Summary

Edge embeddings provide a powerful way to study and analyze networks by capturing the complex relationships between nodes. In the context of a social network, they enable effective link prediction, helping us understand and predict the dynamics of user interactions and friendships.

