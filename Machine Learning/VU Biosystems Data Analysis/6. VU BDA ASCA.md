# ASCA

[0. VU BDA](0.%20VU%20BDA.md)

## ANOVA vs. Linear model

- ANOVA uses group means to calculate effect of factor levels
	- ex. mean gene expression in each group
	- does not work well in unbalanced settings: unequal number of samples in each group
- Linear models: estimate effect size by minimization of residuals over all levels simultaneously
	- Equal to ANOVA in balanced settings
	- Better than ANOVA in unbalanced settings
- ASCA: ANOVA for many variables + PCA
- ASCA+: Linear model for many variables + PCA

## ANOVA

- Look for differences between groups
	- Test the effect of a treatment
- Assumptions:
	- Normally distributed
	- Equal variance
- When the assumptions are not met
	- Non-parametric test
	- Kruskal-Wallis test

## One-way ANOVA

### Notation

$$y_{i_{k}}$$: factor y, level i, and replicate k

### Model

$$y_{i_k}=\mu+\alpha_i+\varepsilon_{i_k};\varepsilon_{i_k}\thicksim\mathbb{N}(0,\sigma^2)$$
y is made up of:
- overall mean $\mu$
- contribution from factor i, $\alpha_i$
- deviation from the mean, which is normally distributed $\varepsilon_{i_k}\thicksim\mathbb{N}(0,\sigma^2)$
	- note the variance of the normal distribution is the same for all i levels
	- the sum of all variance from the mean is 0

### Estimates

$$\begin{aligned}y_{i_{k}}&=y_{..}+(y_{i.}-y_{..})+(y_{i_{k}}-y_{i.})\\y_{..}&=\frac{\sum_{i=1}^{I}\sum_{k=1}^{K}y_{i_{k}}}{IK}\\y_{i.}&=\frac{\sum_{k=1}^{K}y_{i_{k}}}{K}\end{aligned}$$
- $y_{..}$: total mean
- $y_{i.}$: group mean
- $y_{i_{k}}-y_{i.}$: deviation from the group mean
- similar to LDA
- separation of between group variance and within group variance

### Sum of squares

The sums of squares is defined as: $$\begin{aligned}\sum_{i=1}^I\sum_{k=1}^K\left(y_{i_k.}-y_{..}\right)^2&=\sum_{i=1}^I\sum_{k=1}^K(y_{i.}-y_{..})^2+\sum_{i=1}^I\sum_{k=1}^K\left(y_{i_k.}-y_{i.}\right)^2\\\sum_{i=1}^I\sum_{k=1}^K\left(y_{i_k.}-y_{..}\right)^2&=K\sum_{i=1}^I(y_{i.}-y_{..})^2+\sum_{i=1}^I\sum_{k=1}^K\left(y_{i_k.}-y_{i.}\right)^2\end{aligned}$$
- total sum of square = sum of squares for between group + sum of squares for within group
- The cross product of squaring is 0 by the orthogonality of design.
- in balanced situation the cross product is 0

## Two-way ANOVA

- Two treatments A and B
- Is there an overall treatment effect
- Is there an effect for treatment A
- Is there an effect for treatment B
- Is there an interaction effect

### Interaction effect: example

- If the effect of A depends the level of B

### 2 factor design

- equal sample size for each combination of factors

### Model

$$y_{ij_k}=\mu+\alpha_i+\beta_j+(\alpha\beta)_{ij}+\varepsilon_{ij_k};\varepsilon_{ij_k}\sim\mathrm{N}(0,\sigma^2)$$
- $\mu$: total mean
- $\alpha_i$: main effect of A
- $\beta_j$: main effect of B
- $(\alpha\beta)_{ij}$: interaction effect; note $(\alpha\beta)$ does not mean multiplication of $\alpha$ and $\beta$
- $\varepsilon_{ij_k}$: deviation from the mean, follow a normal distribution

### Estimates


### Sum of squares


## Linear model for 2-way ANOVA

- In unbalanced situation ANOVA is not suitable. Linear model is better
- $$\begin{aligned}y&=X\theta+e\\y&=y_{intercept}+y_{treatment}+y_{time}+y_{time:treatment}+e\end{aligned}$$
	- $y$: response
	- $X$: model matrix, quantitative or categorical factors, contains information on the groups
	- $\theta$: slopes or estimates for group effects by linear regression
	- $e$: residuals (within group variation), expected to be the same for all groups
- $$X\theta=y_{intercept}+y_{treatment}+y_{time}+y_{time:treatment}$$
	- $\theta$ contains the $\mu$, $\alpha_i$, $\beta_j$, $(\alpha\beta)_{ij}$ values
	- $X$ contains the structure to connect the correct coefficients to the corresponding samples
	- Fist column of $X$ contains only 1s for estimation of $\mu$

### Coding for categorical factors

- Dummy coding: one-hot encoding
	- Matrix becomes non-invertible: for example, 4 rows for each time point, 4+1 columns for each time and the coefficients for the mean
	- It cannot be used for regression
- To resolve this problem, note that the total deviation from the total mean must sum to 0. Therefore, if we know the deviations from the total mean for all levels but 1, the last deviation can be calculated. So it does not need to be stated explicitly. This is the cause of redundant information. Same idea is involved in [Degree of freedom](Bessel's%20Correction.md#Degree%20of%20freedom).
- Reference coding: coefficient ($\beta$) for T1 is 0, the other describe deviation from T1.
	- Put 0 for other levels
- Sum coding: 
	- coefficient for T1 is $0-(\beta_{T_2}+\beta_{T_3}+\beta_{T_4})$, when there are 4 levels.
	- The coefficients are deviations from total mean. 
	- For the reference level, put -1 for columns corresponding to other levels. For the other levels, put 0 for columns corresponding to other levels (see example table below).

#### Example

This is the $X$ matrix of the linear model.

**Dummy coding**

| Time    | I   | T1  | T2  | T3  | T4  |
| ------- | --- | --- | --- | --- | --- |
| 1 (ref) | 1   | 1   | 0   | 0   | 0   |
| 2       | 1   | 0   | 1   | 0   | 0   |
| 3       | 1   | 0   | 0   | 1   | 0   |
| 4       | 1   | 0   | 0   | 0   | 1   |
- The rows of the table: levels being coded.
- The columns of the table: dummy variables indicate which level does the observation belongs to.
- For example, level 2 would be coded as $[0,1,0,0]$.
- There is redundant information, leading to more columns than rows.

**Reference coding**

| Time    | I   | T2  | T3  | T4  |
| ------- | --- | --- | --- | --- |
| 1 (ref) | 1   | 0   | 0   | 0   |
| 2       | 1   | 1   | 0   | 0   |
| 3       | 1   | 0   | 1   | 0   |
| 4       | 1   | 0   | 0   | 1   |
- Using mean of level 1 as reference.
- Coefficients describe deviations from the mean of level 1.

**Sum coding**

| Time    | I   | T2  | T3  | T4  |
| ------- | --- | --- | --- | --- |
| 1 (ref) | 1   | -1  | -1  | -1  |
| 2       | 1   | 1   | 0   | 0   |
| 3       | 1   | 0   | 1   | 0   |
| 4       | 1   | 0   | 0   | 1   |
- Coefficients describe deviation from the total mean.

#### Sum coding vs. reference coding

Why use sum coding over reference coding?

- If the reference level chosen for reference coding is an outlier, the coefficients estimated are less informative.
- Using sum coding allows evaluating how each group deviates from the grand mean. This gives a broader view of the effects across all levels rather than being tied to a reference level.
- It may not make sense to choose 1 level as the reference when all groups are equally important in experiment design.