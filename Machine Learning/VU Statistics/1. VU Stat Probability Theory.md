# Probability Theory

[0. VU Statistics](0.%20VU%20Statistics.md)

## Probability concepts

### A discussion: correlation between chocolate consumption and the number of Nobel laureates 

- Dependence: when 1 variable changes with another variable
- Conditional probability: $P(x|y)$ probability of $x$ given $y$
- Statistical significance: p value
- Scientific significance
- Mechanism behind correlation

### Concepts from probability theory

- **Experiment**: obtaining one or more observations from purely observational to highly controlled
- **Sample space**: the set of all possible outcomes of an experiment
	- Ex. rolling a die $\Omega_\text{die}=\{1,2,3,4,5,6\}$ 
- **Event**: doing an experiment and making an observation or a combination of observations
	- An event is a subset of the sample space
		- Ex. observing an odd number of pips $E_{odd} = \{1,3,5\}$
	- We can speak of _probability of an event_
- **Event space**: the set of all events
	- The Event space is a set of sets, specifically a $\sigma$-algebra (definition, see syllabus)
	- The Event space includes $\Omega$, the _Certain Event_, and $\varnothing$, the _Impossible Event_
	- Ex. $\Sigma = \{E_{even},E_{odd},\Omega_{die},\varnothing\}=\{\{1,3,5\},\{2,4,6\},\Omega_{die},\varnothing\}$ 

$\sigma$-algebra
## Probability

### Probability of events

- for a continuous variable, always need to be a range
- probability of observing an even number of pips on a die (1/2)
- probability of observing an even or odd number of pips on a die (1)
- probability of observing blood glucose concentration in the range \[4,6\] $mM$ in the general population at 10AM.

### Interpretation of probability

- [MLE vs. Bayesian Views on Probability](MLE%20vs.%20Bayesian%20Parameter%20Estimation.md#MLE%20vs.%20Bayesian%20Views%20on%20Probability)
- Long term frequency of observing the Event when performing many, many Experiments (frequentist view)
- Quantification of our belief that the Event will be observed when we perform an Experiment (Bayesian view)

### Axioms of probability

- $P(A)\ge 0$ for any event $A$
- $P(\Omega) = 1$
- If $A$ and $B$ are _disjoint_ events then $P(A\cup B) = P(A) + P(B)$. $\cup$ means combination of $A$ and $B$.
	- If $A$ and $B$ are _disjoint_ events then $P(A\cap B) = \varnothing$. $\cap$ means intersection of $A$ and $B$.

### Conditional probability

![](Pasted%20image%2020241107141416.png)

The conditional probability is defined as: $$P(A|B)=\frac{P(A\cap B)}{P(B)}$$, similarly: $$P(B|A)=\frac{P(A\cap B)}{P(A)}$$
- P(B) is called the normalization term. It scales $P(A\cap B)$ back to \[0,1\]; [The constant of integration](MLE%20vs.%20Bayesian%20Parameter%20Estimation.md#^e7c1f2)

### Product rule and law of total probability

From the definition of conditional probability, we have the **product rule**: $$P(A\cap B)=P(A|B)P(B)$$
In the case of many events $A_1,A_2,\ldots,A_n$ that forms a **partition set** of $\Omega$, we have the **law of total probability**: $$P(B) = \sum^n_{i=1}p(B\cap A_i)=\sum^n_{i=1}P(B|A_i)P(A_i)$$
![](Pasted%20image%2020241107143448.png)
**Partition set** of $\Omega$: A set $\mathcal{F}=\{A_1,\ldots A_n\}$ of disjoint subsets of $\Omega$ whose union equals $\Omega$: $A_i\subset\Omega$ and $A_i \cap A_j = \varnothing$ when $i\ne j$ and $A_1\cup A_2\cup\ldots\cup A_n=\Omega$

### Bayes rule

From the product rule: $P(A\cap B)=P(A|B)P(B)=P(B|A)P(A)$

We have the **Bayes rule**: $$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$$
When given conditional probabilities on a partition set $\mathcal{F}={A_1,\ldots,A_n}$: $$P(A_j|B)=\frac{P(B|A_j)P(A_j)}{\sum^n_{i=1}P(B|A_i)P(A_i)}$$. The bottom uses the law of total probability.

### Independence of events

Two events $A$ and $B$ are independent when $$P(A|B)=P(A)$$, otherwise they are dependent.

In words, this means:
- observing $B$ does not change the probability of observing $A$
- observing $B$ is uninformative for observing $A$
- Events A and B do not carry _mutual information_

This implies: $$P(A\cap B)=P(A)P(B)$$ and $$P(B|A)=P(B)$$

### Conditional independence

$$P(A,B|Z) = P(A|Z)*P(B|Z)$$

## Probability distributions

### Random variable

A **random variable** is a function that maps every outcome in a Sample space to a number (usually from $\mathbb{N}, \mathbb{Z}\ or\ \mathbb{R}$).

Reason: use these numbers as input for probability distribution functions to enable the calculation of probabilities.

### Probability distribution



## Expectations

### Expected value of a random variable

- Weighted sum of each value the random variable can take by the probability of it taking this value
$$
\mathbb{E}[X]=\sum_ixP(X=x)
$$

### Expected value of a function

- A function transforms a random variable

$$
\mathbb{E}[g(X)]=\sum_ig(x)P(X=x)
$$

### Expected value of a constant

$$
\mathbb{E}[a]=a
$$
especially: $$\mathbb{E}[\mathbb{E}[X]]=\mathbb{E}[X]$$
### Linearity

$$\begin{aligned}
\mathbb{E}[aX] & =a\mathbb{E}[X] \\
\mathbb{E}[X+Y] & =\mathbb{E}[X]+\mathbb{E}[Y]
\end{aligned}$$

### Population variance

$$
\begin{aligned}
\mathrm{var}(X)&=\mathbb{E}\left[(X-\mathbb{E}[X])^2\right]\\
\mathrm{var}(X)&=\mathbb{E}[X^2]-\mathbb{E}[X]^2
\end{aligned}
$$

### Independent, identically distributed samples

- A set of independent samples $X_i$ drawn from the distribution of a random variable $X$ is called a set of Independent, Identically Distributed samples (i.i.d.) samples.
- **Independent**: the value of $X_j$ is independent of the the values of $X_i$ where $i\ne j$.
- **Identically distributed**: all $X_i$ are random variables with the same properties as $X$. In particular: $$\forall i:\quad\mathbb{E}[X_i]=\mathbb{E}[X]$$
- for all i, expected value of $X_i$ is the expected value of $X$

### Unbiased estimator

For an unbiased estimator $\hat{Z}$ of a random variable $Z$ the following must hold:
$$E[\hat{Z}]=E[Z]$$

Suppose $X_i$ is a set of i.i.d. samples of $X$.

The sample mean $\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i$ is an unbiased estimator of $E[X]$, i.e.
$$E[\bar{X}] = E[E[X]] = E[X]$$

Proof: follows immediately from linearity of the Expectation operator.

The sample variance $s^2(X_i) = \frac{1}{n-1} \sum (X_i - \bar{X})^2$ is an unbiased estimator of $var(X)$, i.e.

$$\mathbb{E}\left[\frac{1}{n-1}\sum_{i=1}^n\left(X_i-\overline{X}\right)^2\right]=\mathbb{E}[\mathrm{var}(X)]=\mathbb{E}\left[\left(X-\mathbb{E}[X]\right)^2\right]$$

